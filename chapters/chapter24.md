---
title: 'Chapter 2.4: Machine Learning - Gradient Boosting Machines'
description:
  'Finally, the cool bit.'
prev: /chapter23
next: /chapter25
type: chapter
id: 3
---

<slides source="chapter24_gbm">
</slides>

<exercise id="1" title="Steps to build a GBM">

What isn't a step to build a GBM?

<choice id="1">

<opt text="An additive model to add  weak learners to mimize the loss function.">
</opt>

<opt text="An independent model to isolate learners to mimize the loss function." correct="true">
</opt>

<opt text="A weak learner to make predictions.">
</opt>

<opt text="A loss function to be optimized.">
</opt>

</choice>

</exercise>

<exercise id="2" title="Base learners commonly used for GBMs">

What type of model is the most common base learner for a GBM?

<choice>

<opt text="Linear regression">
</opt>

<opt text="Support Vector Machines">
</opt>

<opt text="Random Forests">
</opt>

<opt text="Decision Trees" correct="true">
</opt>

</choice>

</exercise>

<exercise id="3" title="Common parameters to control GBM weak learner overfitting">

Which of the following aren't options to control overfitting in GBM base learners?

<choice>

<opt text="Nodes">
</opt>

<opt text="Splits">
</opt>

<opt text="Leaf nodes">
</opt>

<opt text="Number of trees" correct="true">
</opt>

</choice>

</exercise>
